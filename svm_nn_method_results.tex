\section{Proposed occupancy estimation approaches}
In this section we apply the SVR and neural network approach on occupancy estimation in a smart building that contains five zones. The whole smart building is simulated by using the energy simulation tool \EP{}. We will first discuss the principles based on the features used for detection and then conduct the data configuration used in the model for occupancy detection.
\subsection{Feature Selection}
\begin{figure}[h]
\centering
\includegraphics[width=4in]{./Pics/TopView2.eps}
\caption{The office model: top view.}
\label{fig:office1}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=4in]{./Pics/SideView.eps}
\caption{The office model: side view.}
\label{fig:office2}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=4in]{./Pics/Headcount.eps}
\caption{Occupation information of 5 rooms for 10 days.}
\label{fig:Headcount}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=4in]{./Pics/Feature3.eps}
\caption{Selected \EP{} input and simulated temperature output data sample in 20 days. (WT: Work Time; OT: Outdoor Temperature; IT: Indoor Temperature; SL: Solar Angle; LE: Lights Energy; PC: People Count.)}
\label{fig:feature}
\end{figure}

In the machine learning model we built for occupancy detection, we
carefully selected 5 features each of which possesses some unique
information hidden inside. The features are solar angle, indoor
temperatures, outdoor temperatures, working time, and lights energy.
Solar angle is believed to have periodic information which varies
across the entire year, outdoor temperature is an apparent factor that
impacts the indoor temperature, working time denotes whether regular
working schedule is executed, and lights energy gives out a radiation
metric that causes rise of the temperature.

Fig.~\ref{fig:office1} and Fig.~\ref{fig:office2} show the side view
and the top view of the building which contains five rooms and HVAC
system by using the software \EP{}. This building can be
influenced by heat sources produced from occupants, electric
equipment, air filtration, etc. The weather (ambient temperature and
solar effects) affects the room temperature as well. Through the HVAC
system with coil and fan, room temperature can be administered
properly to ensure that a comfortable temperature in the environment
can be produced in the room.

In this room the solar angle ${\theta _s}$ is defined as the angle between the zenith and the centre of the sun disc
\[\cos {\theta _s} = \sin \phi \sin \delta  + \cos \phi \cos \delta \cosh \]
where $h$ is the hour angle in the local solar time, $\delta$ is the
current declination of the sum, and $\phi$ is the local latitude. This
equation enables us to compute the feature solar angle and all the
variables are correlated to the location of the building.

Working time is a feature that determines if the time detected is
local working time or not, and it apparently affect the number of
working people in a certain office. It is also convenient to achieve
schedule of an ordinary worker in an office within the building and it
is a good feature contributing to the detection. When a feature is
being considered to be incorporated in the feature pool, we first
figure out the convenience and difficulty in acquiring the data set.
Here the working time has a strong correlation with the employee common
schedule, which is a relatively data set to acquire. Therefore, the
working time is chosen as a feature element in the feature pool, and
it is even a basic feature owing to its convenience.

Outdoor temperatures are off-the-rack data set collected from weather
forecast which also are the inputs for \EP{} to generate indoor
temperatures data as an output. Herein we use the outdoor
temperature data set of the location of the building in Chicago, so as
our simulated building model goes through the exact same weather
conditioning the genuine building has gone through. And outdoor
temperatures also plays an instrumental feature role in detection,
because it directly influences the indoor temperature, which has a
non-linear relationship with the number of employees in a certain
office.

The indoor temperature turns out to be one of the key features used in
the detection model, to be more accurately, all of the factors
including employee occupancy constitute the list of elements that
results in the fluctuation of temperature inside the building. In
essence, the approach to achieve the detection for a number of
employee in a certain room is based on the contribution of heat
emitted from different number of employees in a certain room. Owing to
the fact that different number of employees gives out different amount
of heat to impact the indoor temperature, makes the approach viable to
detect the occupancy combing other factors that affect the indoor
temperature.

Lights energy is the fifth feature in the feature pool, and it is
different from the first four. The first four features are quite
convenient features to acquire where the measurement of lights energy
is comparatively inconvenient to acquire. However, we want to make the
detection more versatile and can be applied in different situations.
Despite the inconvenience of data set of lights energy, it is an
important metric related to the number of employees in a specific office
as well. Aiming at provide a more accurate detection, the lights
energy feature is incorporated into the feature pool.

As listed above, five features are applied in the machine learning
method we apply in our approach. In keeping with different degree to
application, different combination of features are used in the
methods, which makes the application more flexible.

\subsection{Data Configuration}
\begin{figure}[!h]
\centering
\includegraphics[width=4in]{./Pics/FlowDiagram2.eps}
\caption{Data configuration of machine learning model.}
\label{fig:SVRFlow}
\end{figure}

Fig. \ref{fig:SVRFlow} shows how \EP{} produces indoor temperature
in a certain room specifically. \EP{} feeds off factors such as
indoor temperature, solar factor, electrical factor, light factor,
infiltration, infrared, and people occupancy before it produces indoor
temperature as an output using built-in methods and methods in
accordance with its inputs. Of all those features taken into the
method, indoor temperature is the key feature because it is directly
impacted by the increase or drop in the number of employees in a
certain office.

In general, the machine learning model takes the selected parameters
as its features to train the data and yield results. It is highlighted
that the relationship between occupancy and other factors are
non-linear related, where SVR and neural network are good choices to
solve a non-linear problem used for detection. And machine methods are
increasingly used in all kinds of supervised and unsupervised problems
in all aspects.

Fig.~\ref{fig:Headcount} shows a vintage working schedule of the five
zones of an office building. Our goal of the detection model is to
detect accurate number of employees in a room by certain parameters
and data collections. Fig.~\ref{fig:feature} shows the simulated
temperature curves and input curves over 20 days from \EP{} for a
smart building model with the five separate zones shown in
Fig.~\ref{fig:office2}. The schedule for each room can be assigned
differently by \EP{}. The selected features are then combined
together to occupancy behavior in the smart building. In general, the
SVR model takes the selected features as its parameters to train the
data and yield the corresponding results. It should be noted that
there is a nonlinear relationship between the occupancy and the
related factors. The machine learning model can be used to solve this
nonlinear problem for occupancy detection.

In this model, we provide two sets of model which offers different
extent of convenience to detect number of employees in an office. The
first set of model is comprised of features such as solar factor,
working time, indoor temperature and outdoor temperature, data of
which can be acquired through sole mathematic computation and
\EP{} simulation. It is relatively convenient to obtain all the
features required in the first feature set. However, we introduce one
more features in the second feature set, light factor, to enhance the
accuracy of model. Light factor requires the model to learn overall
energy that light consumes during a certain quantity of time which is
a comparatively inconvenient feature to obtain, however, it is capable
of making the detection more accurate. It is also highlighted here
that all of the data we feed in the model is generated from \EP{}
or obtained through mathematical calculation, thus further experiments
are likely to be conducted in real-life data condition.

For separating the whole data set, we split the one-year simulation
data into twelve months and three time periods, in which the months
1-3, 5-7, 9-11 are referred to as the training data and the months 4,
8, 12 are specified for the testing data in the proposed machine
learning model.

\section{Support Vector Regression Results and Analysis}
In this section, we illustrate how we measure error variation for
the proposed SVR model and discuss the effectiveness of applying
different number of features in this model.

\subsection{Experimental Results}
\begin{table}[!h]
\label{table:training}
\caption{Training error statistics of SVR model using different numbers of features.}
\centering
\begin{tabular}{m{1.2cm}m{0.8cm}m{0.8cm}m{0.8cm}m{0.8cm}m{0.8cm}m{0.8cm}}
\hline
& \multicolumn{2}{c}{$C$=100} & \multicolumn{2}{c}{$C$=500} & \multicolumn{2}{c}{$C$=1000} \\
\cline{2-7}
Features &   \hspace{0.2cm} 4  &\hspace{0.2cm}   5  &\hspace{0.2cm}   4  &\hspace{0.2cm}   5  &\hspace{0.2cm}   4  & \hspace{0.2cm}  5  \\
\hline
Avg. error&0.721& 0.310   & 0.576 &  0.326   &  0.550  &  0.348        \\
Err. ratio&0.311& 0.0856  & 0.188 &  0.0889  &  0.181  &  0.124        \\
\hline
\end{tabular}
\end{table}


\begin{table}[!h]
\label{table:testing}
\caption{Validation error statistics of SVR model using different numbers of features.}
\centering
\begin{tabular}{m{1.2cm}m{0.8cm}m{0.8cm}m{0.8cm}m{0.8cm}m{0.8cm}m{0.8cm}}
\hline
& \multicolumn{2}{c}{$C$=100} & \multicolumn{2}{c}{$C$=500} & \multicolumn{2}{c}{$C$=1000} \\
\cline{2-7}
Features &   \hspace{0.2cm} 4  &\hspace{0.2cm}   5  &\hspace{0.2cm}   4  &\hspace{0.2cm}   5  &\hspace{0.2cm}   4  & \hspace{0.2cm}  5  \\
\hline
Avg. error&0.819& 0.317   & 0.694 &  0.330   &  0.638  &  0.390        \\
Err. ratio&0.068& 0.0264  & 0.0578 &  0.0274  &  0.0532  &  0.0325        \\
\hline
\end{tabular}
\end{table}

We evaluate the SVR detection model using
testing data set. Through a wide range of experiments, we learn radial
basis function kernel also known as Gaussian kernel work best in this
model. The two most important parameters in SVR model are penalty $C$
and radius $\varepsilon$, where plenty of tests are conducted to obtain
a good set of parameter, hence, we experiment different values of $C$
and $\varepsilon$ hoping to obtain the best. It is widely known that
to get an accurate performance in SVR model or any other machine
learning methods, the best approach is to enumerate a quantity of
combinations of parameters, and conduct experiments to drive the
result toward a better trend. During the process of seeking out the
best result for the model, the set of parameters is adjusted step by
step to obtain a model which has a better accuracy than the previous
one. After a batch of experiments for the model are conducted, we pick
out the parameters in the model that brings about the best
performance. Here we also want to highlight, that most of the time,
the parameters working best for a model sometimes can not be proved
theoretically, therefore confirmed parameters often are determined by
a great number of trials and experiments.

Table \rom{1} shows the training error statistics of the proposed SVR
model used for occupancy detection. Some comparisons between two sets
of features are apparently displayed from the results shown in this
table. Numerical simulation shows that $\varepsilon$ being equivalent
to 0.01 is a reliable choice for this SVR-based occupancy model. At
each sample point, the estimation error ${e_i}$ is defined as
${e_i} = \left| {O_i^{SVR} - O_i^{EP}} \right|$ where $O_i^{SVR}$
denotes the occupancy value obtained by the proposed SVR model and
$O_i^{EP}$ denotes the real value of occupancy generated from \EP{}. We calculate the average error and the error ratio by
$\frac{1}{n}\sum\nolimits_n {{e_i}}$ and
$\frac{{Average{\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt}
    error}}{{full{\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt}
    occupancy}}$,
respectively. Also, in this table different values of $C$ are tested
to seek out an accurate model for occupancy detection.

Table \rom{2} shows the validation error statistics of the proposed SVR model. The reason why the 5-feature model performs even better than the 4-feature model for occupancy detection is that the 4-feature model suffers slightly in under-fitting issue which results in a high bias. It is important to determine the parameters which can maintain a balance between under-fitting and over-fitting.
\subsection{Analysis}
\begin{figure}[h]
\begin{minipage}{\textwidth}
\centering\includegraphics[width=5in]{./Pics/100C4Features.eps}
\subcaption{}\label{fig:1a}
(a) 4 features.
\end{minipage}
\hfill

\vspace{3ex}

\noindent\begin{minipage}{\textwidth}
\centering\includegraphics[width=5in]{./Pics/100C5Features.eps}
\subcaption{}\label{fig:1b}
(b) 5 features.
\end{minipage}
\hfill
\caption{Occupancy estimation accuracy when $C$ equals 100 using SVR with 4 features and 5 features.}\label{fig:compare1}
\end{figure}

\begin{figure}[h]
\begin{minipage}{\textwidth}
\centering\includegraphics[width=5in]{./Pics/500C4Features.eps}
\subcaption{}\label{fig:1a}
(a) 4 features.
\end{minipage}
\hfill

\vspace{3ex}

\noindent\begin{minipage}{\textwidth}
\centering\includegraphics[width=5in]{./Pics/500C5Features.eps}
\subcaption{}\label{fig:1b}
(b) 5 features.
\end{minipage}
\hfill
\caption{Occupancy estimation accuracy when $C$ equals 500 using SVR with 4 features and 5 features.}\label{fig:compare2}
\end{figure}

\begin{figure}[h]
\begin{minipage}{\textwidth}
\centering\includegraphics[width=5in]{./Pics/1000C4Features.eps}
\subcaption{}\label{fig:1a}
(a) 4 features.
\end{minipage}
\hfill

\vspace{3ex}

\noindent\begin{minipage}{\textwidth}
\centering\includegraphics[width=5in]{./Pics/1000C5Features.eps}
\subcaption{}\label{fig:1b}
(b) 5 features.
\end{minipage}
\hfill
\caption{Occupancy estimation accuracy when $C$ equals 1000 using SVR with 4 features and 5 features.}\label{fig:compare3}
\end{figure}
In this part of the section, the process of achieving the best model we build is revealed, and several figures of performance for models are displayed to have a direct comparison for the model under different number of figures. The figures mainly display the accuracy when applying 4 features or 5 features in the model, and offers a vivid comparison in those figures.

We now display the accuracy of applying 4 features or 5 features in the proposed SVR model. To obtain the best parameter setting in the SVR model used for occupancy detection, we need to constantly compare the gap between the training and testing errors for the collected data sets by \EP{}. If the gap of accuracy between training and testing errors are relatively large, which means that this model is over-fitting on the training data. In accuracy on training data implies that the model has a potential under-fitting. In this situation, we need to adjust parameters to make the SVR-based model work better.

We randomly pick out a 15-day period from the testing data set and compare it to the genuine value generated by \EP{}. Large number of experiments in this proposed SVR model shows that 0.01 is a stable-performing value for $\varepsilon$. Fig. \ref{fig:compare1}, Fig. \ref{fig:compare2}, and Fig. \ref{fig:compare3} show the simulation results of occupancy detection accuracy of SVR model by using different numbers of feature. To find a better performance model, we set $C$ to be 100, 500, and 1000, respectively. Simulation results show that the SVR model tends to become more complex when the value of $C$ becomes larger, hence the goal of optimizing the SVR model is to find the value of $C$ that is one better tradeoff between under-fitting and over-fitting. For the 5-feature model, it can be seen that the SVR model can obtain better performance for occupancy detection when the value of $C$ varies in the range from 10 to 1000.

The two sets of features provide different convenience in detecting to meet different demand. The first set of features  can be relatively easily acquired while the second set requests more efforts. The first set of feature only requires data set that can be obtained from mathematic computation, whereas the second set  requires light energy which is a set of statistics that needs more effort to achieve. In terms of practical application, it is suggested to choose the one that meets demand and gives the best convenience. However, further improvement can be considered by building model revolving around absorbing the current data set into the SVR model, which makes the model work as a dynamic equation that is able to self-improved by newly absorbed data set and remain more effectively according to the current circumstance. Most importantly, it is suggested to choose the most efficient approach based on the facing situation, after all, the model is able to fulfill ordinary demand in accuracy in 4-feature model. Further improvement is likely to happen if one considers specific conditions for other office in detail.

\section{Neural Network Results and Analysis}
%In this section, results of neural network are achieved and explained similarly as it is manifested in last section. 
The way we measure errors and show the performance of neural network model is a little different owing to the different characteristics of neural network. Further demonstration is expanded in this section, and a set of figures will be shown to judge the performance of neural networks.

\subsection{Results}
\begin{figure}[h]
\centering
\includegraphics[width=4in]{./Pics/NN.eps}
\caption{Neural Network structure.}
\label{fig:nn}
\end{figure}

A two-layer feedforward neural network (FNN) is used herein to build up a model which is able to detect the occupancy in a smart building. Fig. \ref{fig:nn} shows that the neural network we established possesses 8 sigmoid hidden neurons and linear output neurons. The number of neurons in a hidden layer determines the complexity of a neural network, where the more hidden neurons the more likely that the neural network is to get over-fitted. Therefore, in the process of achieving best suitable weights and biases for the model, it is indispensable to apply the early stopping method to obtain a proper set of value for weight and bias. Therefore, FNN is trained with Levenberg-Marquardt back propagation, which is a method widely used in solving non-linear least squares problems. It is relatively faster to acquire the weights and biases we want to set for the whole model. To minimize the sum of the squares of all errors between detected value and data points, least square problems appear when a parameterized function is required to fit a set of original data points. And nonlinear least squares approaches require an iterative process to improve parameters in a model so as to diminish the sum of the squares of the errors shown between the original data points and function. In essence, the Levenberg-Marquardt curve-fitting approach is virtually a combined technique of two minimization methods, the gradient descent and the Gauss-Newton method. The sum of the squared errors is minimized by updating the parameters in the steepest descent direction in gradient descent method. In the Gauss-Newton method, it assumes the least square function as locally quadratic to diminish the sum of the squared errors, thus attempting to seek out the minimum of the quadratic. For the parameters, the Levenberg-Marquardt method uses more like the gradient descent method when there is a large gap between the optimal value and current value, and more like the Gauss-Newton method when there is a small variation between the optimal value and current value.

The method combines advantages of the steepest descent method (that is, minimization along the direction of the gradient) with the Newton method (that is, using a quadratic model to speed up the process of finding the minimum of a function). This method obtained its operating stability from the steepest descent method, and adopted its accelerated convergence in the minimum vicinity from the Newton method. Standard implementation of the Levenberg-Marquardt method (LMA), and its drawbacks are discussed below. When minimizing a nonlinear least-squares function, the Levenberg-Marquardt method can suffer from a slow convergence, particularly when it must navigate a narrow canyon end route to a best fit. On the other hand, when the least-squares function is very flat, the method may easily become lost in parameter space. Several improvements to the Levenberg-Marquardt method are used in order to improve both its convergence speed and robustness to initial parameter guesses. We include a geodesic acceleration correction term, explore a systematic way of accepting uphill steps that may increase the residual sum of squares due to Umrigar and Nightingale, and employ the Broyden method to update the Jacobian matrix. We test these changes by comparing their performance on a number of test problems with standard implementations of the method. We suggest that these two particular challenges, slow convergence and robustness to initial guesses, are complimentary problems. Schemes that improve convergence speed often make the method less robust to the initial guess, and vice versa.

The Levenberg-Marquardt method works as an iterative procedure in solving numeric minimization methods. Before starting minimizing an equation, it is required to assign parameter vector $\beta$ an initial value, this is quite important because the method is able to converge to a global minimum, under the condition that the initial guess is relatively close to the final solution.

In each iteration step, the parameter vector $\beta$ is substituted by a new estimate, $\beta + \delta$. To find $\delta$, the functions $f\left( {{x_i},\beta  + \delta } \right)$ are approached by their linearizations
\[f\left( {{x_i},\beta  + \delta } \right) \approx f\left( {{x_i},\beta } \right) + {J_i}\delta \]
where
\[{J_i} = \frac{{\partial f\left( {{x_i},\beta } \right)}}{{\partial \beta }}\]
works as the gradient of $f$ with respect to ¦Â.

Working through some mathematical computations and reductions, we can get equation
\[\left( {{J^T}J} \right)\delta  = {J^T}\left[ {y - f\left( \beta  \right)} \right]\]

Levenberg's contribution is to substitute this equation for a damped version
\[\left( {{J^T}J + \lambda I} \right)\delta  = {J^T}\left[ {y - f\left( \beta  \right)} \right]\]

At each iteration the $\lambda$ damping factor is adjusted and used to guide the whole optimization process. If reduction of errors is swift, a smaller value is applied to bring the method closer to Gauss-Newton method. On the contrast, $\lambda$ is increased if an iteration exhibits insufficient reduction in residual, thus resulting in a step closer to the gradient descent direction.

\begin{figure}[h]
\centering
\includegraphics[width=4in]{./Pics/msr.eps}
\caption{Epoch and mean squared error.}
\label{fig:Epoch and mean squared error}
\end{figure}

Using a network large enough can provide an adequate fit to improve network generalization, because the functions of the whole network become more complex as the network gets larger. A small enough network is not able to fit the data well, however, neural network often faces over-fitting problem when it is applied into detection.

Fig. \ref{fig:Epoch and mean squared error} shows the curves of mean squared error for training data set, validation data set, and testing data set as epoch gets larger. At the beginning of the training, the mean squared error of three data set all rapidly drops, and the curves of the three different data set look quite close. After a certain time of epochs, the three curves begin to become flat, but the curve of validation data set still proceeds to decreases. At epoch 41, the validation performance achieves its best value 0.76651 which is the minimum of the whole curve of validation performance curve. After 6 epochs, the curve of the validation test still rises, therefore, 41 is selected as the best number for epoch in this model. As seen from the figure, the validation data set and test data set has quite close trends, which also indicates the overall data set are well divided.

\subsection{Analysis}
\begin{figure}[h]
\centering
\includegraphics[width=4in]{./Pics/gradient.eps}
\caption{Gradient, $\mu$, and Validation Check.}
\label{fig:Gradient, Mu, and validation check.}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=4in]{./Pics/instances.eps}
\caption{Error histogram.}
\label{fig:Error histogram}
\end{figure}

One of the problems appearing to be very common in training neural networks is over-fitting. Under this circumstance, the neural network conducts more iterations than necessary during the training process, which may lead to large error on testing data whereas the model performs well on the training data. The network has somehow memorized examples in training data, but fails in detecting data unknown. To solve over-fitting problems existing in neural networks, we apply for early stop method. As for all the data separation, we divide the whole data set into three divisions according to a certain proportion. With 70\% of data used for training, 15\% for validating, and 15\% for testing. Training data is presented to the neural network we build during training, which plays the role in adjusting weights and bias for network. Validation data is used to measure the degree to network generalization, which stops the training process if the performance of validation data starts to decline. Testing data has no impact on the whole training process which is an independent measure of network performance.

The number of iterations should be applied in training process depends on the curve change of validation error. During the initial phase of training, the validation error declines as the training set error declines. When the network starts to over-fit the data, the error on validation set has a trend to go up. The training procedure is stopped under the situation that the validation error has increased for a certain number of iterations, and the network returns the weights and biases under current training when the validation error is at its minimum. In this model, 6 is a relatively safe number for the epoch to stop increasing, which means the training process is ceased when the validation test is monitored to have increased in row for 6 epochs. The test set error is applied for evaluating different models with different weights and biases, the plot of which is also giving a clear trend of how the test error changes. It implies a poor division of data if there is a significant variance between the test error and validating error.



\begin{figure}[h]
\centering
\includegraphics[width=5in]{./Pics/output.eps}
\caption{Regression check.}
\label{fig:Regression check}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=5in]{./Pics/people.eps}
\caption{Occupancy estimation from neural network.}
\label{fig:occupancy estimation from neural network}
\end{figure}

Fig. \ref{fig:Gradient, Mu, and validation check.} shows curves of three different values in the training procedure. The curve of gradient of the model constantly drops before epoch 41, and twisters for a few epochs before the epoch reaches 47. From the changing curve we can tell, 41 is a turning point for the training model, and it turns out to be the best ending epoch in this neural network. In comparison, the changing trend of $\mu$ curve is relatively not regular, but it turns out to get smaller on an overall perspective. At the bottom lies the validation check figure, as seen from the figure, the training process is ceased owing to the monitored straight 6 epochs increase in validation check, which well fits for the early stopping theory.

On Fig. \ref{fig:Error histogram}, the red bars denotes testing data, the green bars denote validation data, and the blue bars denote training data. Outliers can be easily spotted from the error histogram, for they fit apparently worse than most data points. If many data points are significantly different than the rest of the data points, it is suggested to check if there is some inherent in the original data set. More data points should be collected and trained in the neural network to detect the problem. As seen from Fig. \ref{fig:Error histogram}, the majority of errors lie close to the zero error mark, which signifies quite accurate fit for the neural network. Though there are some segments of error scatter a little distance from the zero error mark, the total number of them is comparatively low, which demonstrates that the neural network performs quite accurately in detecting outcome.

Regression is a statistical instrument for detecting the relationships
among variables in statical modeling. The focus is on the
relationship between different variables, and it includes many
techniques and skills in modeling and analyzing variables. In essence,
it is a helpful method to learn how a value of a variable changes when
the other is varied or held fixed. More often than not, given the
independent variables the regression analysis is able to estimate the
conditioned expectation of the dependent variable. Fig.
\ref{fig:Regression check} shows the regression analysis of the result
produced through the neural network. The regression plots manifest the
network outputs with respect to targets for training, validation, and
test data sets. On a perfect regression, the data should match into a
forty-five regression line where the targets equal the outputs from
neural network. The four sub figures respectively represent the
regression analysis for training, validation, test, and all. From the
figures, the overall outputs have a relatively accurate value
corresponding to targets. The value of R respectively for training,
validation, test and all, is 0.98019, 0.98158, 0.97596 and 0.97974,
which indicates that the neural network perform well in detecting
unknown data points.

Fig. \ref{fig:occupancy estimation from neural network} shows the
comparison of occupancy estimation between the original data points
and the detected value from neural network. As seen from the figure,
the overall accuracy of the detected value is relatively close, but
there is a quite variation at the steepest part on the curve. We
believe it is able to mitigate the variance by inducting more features
to enhance the performance of neural network model.

From all above figures we can tell, the overall performance of neural
network is relatively accurate. However, in contrast to mathematical
based on SVR, the overall error is larger whereas the curve of the
detected result fits better than its counterpart in SVR. In neural
network, only 5-feature model is set up and it shows similar accuracy
on occupancy detection. A conclusion is drawn from the comparison of
the two different approaches that what influences the model more is
the features and the number of data points while virtually the two
different methods work similarly well for solving this problem.
